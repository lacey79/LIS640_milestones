{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c88694e-19f3-4e1f-ac31-1c8ca11080ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import t\n",
    "\n",
    "orch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759baafa-024b-45ef-9f1f-c5864bb579c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load datasets\n",
    "flu_ili = pd.read_csv('data/flu_surveillance/flu-ili-byregion-fluseason.csv')\n",
    "flu_clinicallab = pd.read_csv('data/flu_surveillance/flu-clinicallab-byregion-fluseason.csv')\n",
    "flu_publichealthlab = pd.read_csv('data/flu_surveillance/flu-publichealthlab-byregion-fluseason.csv')\n",
    "vaccination = pd.read_csv('data/vaccination/hcp_flu_vaccination_by_hospital_and_county_2017-18_season_072419.csv')\n",
    "weather = pd.read_csv('data/weather/avg_temp_0920.csv', skiprows=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7602d5-8a51-4c74-8a13-42b1726174d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "flu_ili = flu_ili[['date_code', 'Total_ILI', 'Total_Patients_Seen', 'Percent_ILI']]\n",
    "flu_clinicallab = flu_clinicallab[['date_code', 'Number_Positive', 'Percent_Positive']]\n",
    "flu_publichealthlab = flu_publichealthlab[['date_code', 'Count']]\n",
    "vaccination = vaccination[['Influenza_Season', 'County', 'HCP_Percent_Vaccinated']]\n",
    "weather = weather[['Date', 'Value']].rename(columns={'Date': 'date_code', 'Value': 'Avg_Temp'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9732af57-faa8-4dc1-947f-a045900edae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_code</th>\n",
       "      <th>Avg_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200901</td>\n",
       "      <td>46.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200902</td>\n",
       "      <td>45.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200903</td>\n",
       "      <td>49.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200904</td>\n",
       "      <td>54.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200905</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_code  Avg_Temp\n",
       "0     200901      46.9\n",
       "1     200902      45.2\n",
       "2     200903      49.2\n",
       "3     200904      54.3\n",
       "4     200905      66.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c548ff-5bf1-4b25-bdb2-09dce9dd2a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "merged_data = flu_ili.merge(flu_clinicallab, on='date_code', how='left')\n",
    "merged_data = merged_data.merge(flu_publichealthlab, on='date_code', how='left')\n",
    "merged_data = merged_data.merge(weather, on='date_code', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ced829-8080-43a2-84f7-6e078336080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_code                    0\n",
      "Total_ILI                    0\n",
      "Total_Patients_Seen          0\n",
      "Percent_ILI                 29\n",
      "Number_Positive           2508\n",
      "Percent_Positive       2520096\n",
      "Count                     2508\n",
      "Avg_Temp                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# forward-fill \n",
    "merged_data['Avg_Temp'].fillna(method='ffill', inplace=True)\n",
    "# Backward-fill in case of missing values at the start\n",
    "merged_data['Avg_Temp'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# weekly median temperature\n",
    "merged_data['year'] = merged_data['date_code'].astype(str).str[:4].astype(int)\n",
    "merged_data['week'] = merged_data['date_code'].astype(str).str[4:].astype(int)\n",
    "weekly_median_temp = merged_data.groupby('week')['Avg_Temp'].median()\n",
    "\n",
    "merged_data['Avg_Temp'] = merged_data.apply(\n",
    "    lambda row: weekly_median_temp[row['week']] if pd.isnull(row['Avg_Temp']) else row['Avg_Temp'], axis=1\n",
    ")\n",
    "\n",
    "# Drop extra columns if not needed later\n",
    "merged_data.drop(columns=['year', 'week'], inplace=True)\n",
    "\n",
    "# no missing values\n",
    "print(merged_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107b9480-f0dc-45f6-91fa-d6800ee35a56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_code                   0\n",
      "Total_ILI                   0\n",
      "Total_Patients_Seen         0\n",
      "Percent_ILI                 0\n",
      "Number_Positive             0\n",
      "Percent_Positive            0\n",
      "Count                       0\n",
      "Avg_Temp                    0\n",
      "Number_Positive_missing     0\n",
      "Percent_Positive_missing    0\n",
      "Count_missing               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# median imputation for influenza surveillance features\n",
    "flu_features = ['Total_ILI', 'Total_Patients_Seen', 'Percent_ILI']\n",
    "merged_data[flu_features] = merged_data[flu_features].fillna(merged_data[flu_features].median())\n",
    "\n",
    "# missing indicators for lab-related data\n",
    "lab_features = ['Number_Positive', 'Percent_Positive', 'Count']\n",
    "for feature in lab_features:\n",
    "    merged_data[f'{feature}_missing'] = merged_data[feature].isnull().astype(int)\n",
    "    merged_data[feature].fillna(0, inplace=True)  # Assume missing means no reports\n",
    "\n",
    "# final missing values\n",
    "print(merged_data.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b3f44e4-c115-401d-b679-7cdeb507fba3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_code</th>\n",
       "      <th>Total_ILI</th>\n",
       "      <th>Total_Patients_Seen</th>\n",
       "      <th>Percent_ILI</th>\n",
       "      <th>Number_Positive</th>\n",
       "      <th>Percent_Positive</th>\n",
       "      <th>Count</th>\n",
       "      <th>Avg_Temp</th>\n",
       "      <th>Number_Positive_missing</th>\n",
       "      <th>Percent_Positive_missing</th>\n",
       "      <th>Count_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200140</td>\n",
       "      <td>3</td>\n",
       "      <td>135</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200140</td>\n",
       "      <td>25</td>\n",
       "      <td>1211</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200140</td>\n",
       "      <td>2</td>\n",
       "      <td>336</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200140</td>\n",
       "      <td>20</td>\n",
       "      <td>529</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_code  Total_ILI  Total_Patients_Seen  Percent_ILI  Number_Positive  \\\n",
       "0     200140          3                  135         2.22              0.0   \n",
       "1     200140         25                 1211         2.06              0.0   \n",
       "2     200140          0                    0         1.65              0.0   \n",
       "3     200140          2                  336         0.60              0.0   \n",
       "4     200140         20                  529         3.78              0.0   \n",
       "\n",
       "   Percent_Positive  Count  Avg_Temp  Number_Positive_missing  \\\n",
       "0               0.0    0.0      46.9                        1   \n",
       "1               0.0    0.0      46.9                        1   \n",
       "2               0.0    0.0      46.9                        1   \n",
       "3               0.0    0.0      46.9                        1   \n",
       "4               0.0    0.0      46.9                        1   \n",
       "\n",
       "   Percent_Positive_missing  Count_missing  \n",
       "0                         1              1  \n",
       "1                         1              1  \n",
       "2                         1              1  \n",
       "3                         1              1  \n",
       "4                         1              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e915e6c9-52d9-4435-afa3-06501aa3c484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(merged_data.iloc[:, 1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e227c923-1cba-4cc9-a1c6-7a1a89b37639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to PyTorch Dataset\n",
    "class FluDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx, :-1], self.data[idx, -1]  # Features, Target (assumed last column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055ca47a-0985-4250-9b84-becc96b01f05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 11840564\n",
      "Validation dataset size: 2537263\n",
      "Test dataset size: 2537265\n"
     ]
    }
   ],
   "source": [
    "# convert NumPy array to PyTorch TensorDataset\n",
    "scaled_tensor = torch.tensor(scaled_features, dtype=torch.float32)\n",
    "\n",
    "# split into train, validation, test sets\n",
    "train_size = int(0.7 * len(scaled_tensor))\n",
    "val_size = int(0.15 * len(scaled_tensor))\n",
    "test_size = len(scaled_tensor) - train_size - val_size  # Ensure all data is used\n",
    "\n",
    "train_data, val_data, test_data = random_split(scaled_tensor, [train_size, val_size, test_size])\n",
    "\n",
    "# create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader.dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_loader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "180ff2a4-3e83-4a17-bf7e-1d2cec293559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FluPredictorNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FluPredictorNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.BatchNorm1d(128),  # Batch Normalization\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Dropout for regularization\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 1)  # Output layer (regression task)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7465e15-04d0-4448-916c-f1acb968c408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FluPredictorNN(input_size=scaled_tensor.shape[1] - 1).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391629b7-8ae3-4d9d-89bd-06dba493ccea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [07:12<00:00, 428.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.0433, Val Loss: 13.1460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:37<00:00, 666.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 0.0203, Val Loss: 19.3748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [07:34<00:00, 406.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Train Loss: 0.0106, Val Loss: 2.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [07:58<00:00, 386.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Train Loss: 0.0105, Val Loss: 2.3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:46<00:00, 644.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.0244, Val Loss: 3.4853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:47<00:00, 643.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 0.0283, Val Loss: 0.0144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:46<00:00, 646.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 0.0226, Val Loss: 0.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:55<00:00, 625.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 0.0293, Val Loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:51<00:00, 634.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 0.0104, Val Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:50<00:00, 636.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 0.0140, Val Loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:51<00:00, 633.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 0.0097, Val Loss: 0.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [05:05<00:00, 604.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 0.0117, Val Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [19:27<00:00, 158.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 0.0136, Val Loss: 0.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:47<00:00, 642.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 0.0143, Val Loss: 0.0752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:18<00:00, 715.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 0.0146, Val Loss: 0.0261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 185009/185009 [04:58<00:00, 620.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 0.0213, Val Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████▋ | 177944/185009 [04:51<00:11, 594.35it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # progress bar for training\n",
    "\n",
    "# early stopping params\n",
    "patience = 5\n",
    "best_val_loss = np.inf\n",
    "patience_counter = 0\n",
    "\n",
    "num_epochs = 50\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        features, target = batch[:, :-1].to(device), batch[:, -1].to(device).view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # average training loss\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # validation \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            features, target = batch[:, :-1].to(device), batch[:, -1].to(device).view(-1, 1)\n",
    "            predictions = model(features)\n",
    "            loss = criterion(predictions, target)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# best model after training\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252edbfe-706e-4bc9-8665-4cf20e6b7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        features, target = batch[:, :-1].to(device), batch[:, -1].to(device).view(-1, 1)\n",
    "        predictions = model(features)\n",
    "        loss = criterion(predictions, target)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
